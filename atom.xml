<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>CICI&#39;s Blog</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://cicilzx.github.io/"/>
  <updated>2020-05-18T02:45:48.791Z</updated>
  <id>https://cicilzx.github.io/</id>
  
  <author>
    <name>CICI</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>论文翻译 Order Matters:Semantic-Aware Neural Networks for Binary Code Similarity Detection</title>
    <link href="https://cicilzx.github.io/2020/05/09/%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91-Order-Matters-Semantic-Aware-Neural-Networks-for-Binary-Code-Similarity-Detection/"/>
    <id>https://cicilzx.github.io/2020/05/09/论文翻译-Order-Matters-Semantic-Aware-Neural-Networks-for-Binary-Code-Similarity-Detection/</id>
    <published>2020-05-09T02:47:52.000Z</published>
    <updated>2020-05-18T02:45:48.791Z</updated>
    
    <content type="html"><![CDATA[<figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://t1.picb.cc/uploads/2020/05/09/kECSBW.png" alt="论文标题" title>                </div>                <div class="image-caption">论文标题</div>            </figure><p>原文链接：<a href="https://keenlab.tencent.com/en/whitepapers/Ordermatters.pdf" target="_blank" rel="noopener">Order Matters:Semantic-Aware Neural Networks for Binary Code Similarity Detection</a></p><p>发表会议：AAAI-20（CCF A类会议，人工智能）</p><p>二进制代码相似性检测是计算机安全中的一项重要任务，其目标是在不访问源代码的情况下检测相似的二进制函数。传统方法通常使用图匹配算法，但是速度满且不准确。近来，基于神经网络的方法取得了突出成果。一个二进制函数首先被表示为带有手工选择代码块特征的控制流图（CFG），然后用图神经网络计算图嵌入。这些方法更高效和有效，但是不能很好的捕获二进制代码的语义特征。本文我们提出有语义感知的神经网络，用于提取二进制代码的语义信息。特别地，我们使用BERT预训练二进制代码，用于一个token-level任务、一个block-level任务和两个graph-level任务。同时，我们发现CFG节点的顺序对图相似性检测有重要作用，因此我们采用CNN卷积神经网络提取邻接矩阵的顺序信息。我们的实验在2个任务、4个数据集上开展。实验结果表明，我们的方法优于最先进的模型。</p><h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>二进制代码相似性检测用于检测两个给定的二进制函数是否相似，它有很多计算机安全应用场景，如代码克隆检测、漏洞检测、恶意软件检测等。传统方法使用图匹配算法来计算两个函数的相似性。但是，这种基于图匹配的方法速度非常慢，而且很难适应不同的应用场景。近来，一种称之为Gemini的基于神经网络的方法取得巨大成果。图1（左）是一个CFG的例子，Gemini首先将其转化为attributed CFG（右），其中每个代码块的内容为手工选择的特征表示。最后，一个二进制函数可以添加上暹罗式结构，用于计算相似得分和损失得分。Gemini在计算速度和准确率上都优于传统的方法。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://t1.picb.cc/uploads/2020/05/09/kEHV8y.png" alt="图1：控制流图(CFG)及其手动选择块特征的一个例子。" title>                </div>                <div class="image-caption">图1：控制流图(CFG)及其手动选择块特征的一个例子。</div>            </figure><p>尽管基于神经网络的模型已经取得了一些成果，但还有一些重要的东西没有考虑到。首先，如图1所示，每个代码块都被表示为一个人工选择特征的低维度嵌入特征，这会损失一些语义信息。第二，在表示二进制函数时，节点的顺序起着至关重要的作用，而现有方法没有设计相关方法去捕获节点顺序的信息。为了解决这两个问题，我们提出了一个包含三个组成部分的整体框架：语义感知模型，结构感知模型，和顺序感知模型。</p><p>在语义感知模型中，我们使用NLP模型来解析二进制代码的语义信息。CFG代码块中的标识符被视为单词，代码块被视为句子。在现有工作中，Massarelli 使用word2vec模型训练标识符嵌入特征，然后使用注意力机制获取代码块的嵌入。Zuo使用神经机器翻译（NMT）学习跨平台的二进制代码语义特征。本文中，我们使用BERT来与训练标识符和代码块。与BERT类似，我们隐藏部分标识符来预训练蒙面语言模型任务（masked language model，MLM），然后解析所有相邻的代码块来预训练邻接节点任务（adjacency node prediction，ANP）。我们的模型可以同时获取标识符的嵌入和代码块的嵌入，而不是分类学习这两种嵌入。同时，因为我们的最终目标是产生整个图的特征表示，我们增加了两个graph-level的任务。一个用于判断两个代码块是否来源于同一个图，我们将此任务称之为图内代码块任务（block inside graph，BIG）。另一个任务是用于区分代码块属于哪个平台/优化器，称之为图分类任务（graph classification，GC）。我们发现这两个附加的任务可以帮助获取更多语义特征，比更好地学习代码块的特征表示。在预训练完代码块的嵌入特征后，我们调整它们用于graph-level的任务。</p><p>在结构感知模型中，我们使用MPNN和GRU更新函数。 Xu等人证明了图神经网络可以像Weisfeiler-Lehman测试那样具有鉴别力。我们发现在每个步骤中使用GRU可以比直接使用tanh函数存储更多信息。</p><p>在顺序感知模型中，我们试图设计一个结构用于CFG内部节点的顺序。图2展示了一个函数分别在x86-64和ARM平台上获取的两个CFG，和对应的邻接矩阵。这两个CFG有相似的节点顺序，例如节点1都连接了节点2和3，节点2都和节点4、5连接。它们的邻接矩阵非常相似。在探索了许多跨平台函数对之后，我们发现节点顺序的变化很小，基于此，我们提出一种简单的方法用于捕获节点顺序，那就是将邻接矩阵用于CNN模型。我们发现只有3层的CNN效果很好，我们还进一步尝试了其他CNN模型，如Resnet（He等人），并探讨了其他使用学习邻接矩阵的CNN模型。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://t1.picb.cc/uploads/2020/05/09/kEHt2c.png" alt="图2：函数" _freading"在不同平台(x86-64和arm)上的两个cfg和它们的邻接矩阵" title>                </div>                <div class="image-caption">图2：函数"_freading"在不同平台(x86-64和ARM)上的两个CFG和它们的邻接矩阵</div>            </figure><p>我们的贡献有以下几点：</p><ol><li>我们提出了一个通用的框架来学习CFG的嵌入特征，它可以学习语义特征、结构特征和节点顺序特征。</li><li>在语义感知模型中，我们采用BERT来预训练标识符和代码块的嵌入，完成了蒙面语言模型任务（MLM）和邻接点预测任务（ANP）。我们还增加了两个graph-level的任务——图内代码块任务（BIG）和图分类任务（GC），用于更好地表示代码块。</li><li>在顺序感知模型中，我们发现节点顺序很有用，我们将邻接矩阵用于CNN模型，以获取CFG的节点顺序信息，这取得了很大成效。然后我们探索了其他适用于学习邻接矩阵的CNN模型。</li><li>我们基于4个数据集，在2个任务上进行了实验，结果表明我们提出的模型效果优于目前最先进的模型。</li></ol><h1 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h1><h2 id="图神经网络"><a href="#图神经网络" class="headerlink" title="图神经网络"></a>图神经网络</h2><p>图神经网络用于学习图和节点的表示。通过增加深度神经网络的组成，有很多图模型，比如图卷积网络（GCN）、graphSAGE和图注意力网络（GAT）。GCN使用卷积层来更新节点嵌入特征。graphSAGE采用聚合函数来合并节点和邻接节点。GAT使用注意力机制从重要节点中接收更多信息。MPNN设计了一个图表示学习的整体框架，包含一个passing阶段和一个readout阶段。在passing阶段中，通过一些列步骤捕获邻接节点的信息，在readout阶段计算整个图的嵌入。除了MPNN，GN和NLNN也是图学习的整体框架。</p><h2 id="BERT"><a href="#BERT" class="headerlink" title="BERT"></a>BERT</h2><p>BERT是NLP中最前进的预训练模型。BERT利用了Transformer，Transformer是一种学习机制，用于学习文本中单词之间的上下文关系。BERT使用两个策略来训练语言模型。一种是屏蔽语言模型任务（MLM），它是一种自我监督的预测掩码，可鼓励模型捕获有关语言的有用知识。另一个是分类任务，使模型在训练中区分两个句子，这称为下一个句子预测（NSP）。只需在核心模型上添加一小层，即可将BERT用于多种语言任务。在NSP任务中，[cls]令牌通常被视为句子嵌入，并且可以添加映射层以进行微调。BERT预先训练的模型在多种下游任务（例如跨语言模型，问题回答和文本生成）上都取得了很好的结果。</p><h2 id="二进制代码相似性检测"><a href="#二进制代码相似性检测" class="headerlink" title="二进制代码相似性检测"></a>二进制代码相似性检测</h2><p>二进制代码相似性检测是计算机安全中的重要任务。传统方法使用图匹配算法来计算图相似度。 但是，这些方法缓慢且效率低下。一些研究尝试使用图核方法。 最近，Xu提出了一个基于GNN的模型Gemini，该模型比以前的方法有更好的结果。但是它使用手动选择的功能来表示CFG块，该CFG块可能包含的语义信息不足。Zuo在此任务上使用NLP模型，他们将标识符视为单词，将块视为句子，并使用LSTM编码句子的语义向量。为了确保具有相同语义信息的块具有相似的表示形式，它们使用暹罗网络并计算CFG对的余弦距离。他们将已经从同一段源代码编译的两个基本块视为等效。为了获得有标记的代码块对，他们修改了编译器以添加基本块特殊注释器，该注释器为每个生成的汇编块注释唯一的ID。但是，这种方法有两个明显的缺点。 一个是获得相似的块对是一个受监督的过程，需要专家的经验和领域知识，并且某些块无法唯一注释。 另一个是在实际使用中需要针对不同的平台组合训练不同的模型。</p><h1 id="本文的模型"><a href="#本文的模型" class="headerlink" title="本文的模型"></a>本文的模型</h1><h2 id="整体结构"><a href="#整体结构" class="headerlink" title="整体结构"></a>整体结构</h2><p>本文模型输入的是二进制代码函数的CFG，其中每个块都是中间表示的标识符序列。整体结构图如图3所示。在语义感知模型中，模型接收CFG作为输入，然后使用BERT预训练标识符嵌入和块嵌入；在结构感知模型中，使用MPNN和GRU更新函数计算图的语义结构嵌入$g_{ss}$；在顺序感知模型中，模型接收CFG的邻接矩阵作为输入，然后采用CNN计算图顺序嵌入$g_o$。最后，我们将这些都连接起来，使用MLP层计算最终的图嵌入$g_{final}$。</p><script type="math/tex; mode=display">g_{final}= MLP([g_{ss}, g_o])</script><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://t1.picb.cc/uploads/2020/05/15/kYikFw.png" alt="图3：模型整体结构图，包含三个组成部分：语义感知模型、结构感知模型和顺序感知模型" title>                </div>                <div class="image-caption">图3：模型整体结构图，包含三个组成部分：语义感知模型、结构感知模型和顺序感知模型</div>            </figure><h2 id="语义感知模型"><a href="#语义感知模型" class="headerlink" title="语义感知模型"></a>语义感知模型</h2><p>在语义感知建模中，我们提出了具有4个任务的BERT预训练模型来处理CFG。该模型具有几个优点。首先，我们可以从基于同一模型的不同平台，不同架构，不同编译优化选项生成的不同CFG中提取块嵌入。其次，由于我们有一个标识符级的任务，一个块级任务和两个图形级任务，因此可以从预训练过程中同时获得标识符级、块级和图形级信息。第三，训练过程完全基于CFG图，不需要修改编译器或其他操作即可获得相似的块对。</p><p>我们的方法来自NLP中的句子嵌入任务，因为CFG中的块就像句子，块中的标记就像单词。这个任务是解析句子的嵌入，该任务主要有两个方法。一个是有监督的方法，比如文本分类训练；另一个是无监督的方法，比如n-gram特征和编码-解码跳过思想。我们使用基于BERT的改进模型来解析CFG中的块的嵌入。</p><p>如图4所示，在我们预训练的阶段有4个任务。对于节点内的标识符序列，我们使用蒙面语言模型任务（MLM）解析块内的语义信息。MLM是标识符级的任务，它在输入层上屏蔽标识符并在输出层上预测它们。预训练邻接节点任务（ANP）是块级别的任务。在图中，块的信息不仅和块本身的信息相关，还和块的邻居相关，所以我们想让我们的模型学习这样的信息。在ANP任务中，我们解析一个图中所有邻接的块，然后在同一个图中随机采样一些块，来预测两个块是否是相邻的。这两个任务（MLM &amp; ANP）和原始BERT中的MLM &amp; NSP是相似的。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://t1.picb.cc/uploads/2020/05/16/kYAYks.png" alt="图4：BERT和4个任务：MLM,ANP,BIG,GC" title>                </div>                <div class="image-caption">图4：BERT和4个任务：MLM,ANP,BIG,GC</div>            </figure><p>为了更好的利用图的信息，我们增加了两个辅助的有监督任务：图内代码块任务（BIG）和</p><p>图分类任务（GC）。BIG任务和ANP任务类似，区别在于采样不同块对的方式不同。BIG任务试图使模型判别两个节点是否存在于同一个图中。我们随机采样了块对在/不在同一个图中，然后在BIG任务中预测。这个任务帮助模型理解块和图之间的关系，有助于我们图嵌入的任务。在我们的假设中，在不同编译选项下，不同的图和块可能会不一样。为了使我们的模型可以区分这些不同，我们设计了图分类任务（GC），GC可以使模型区分不同平台、不同构建或编译选项的的块。</p><h2 id="结构感知模型"><a href="#结构感知模型" class="headerlink" title="结构感知模型"></a>结构感知模型</h2><p>从BERT预训练获得块嵌入后，我们使用MPNN来计算CFG图中的语义 &amp; 结构嵌入。具有消息函数M和更新函数U的消息传递阶段，运行T个时间步，然后读取函数R计算整个图的语义和结构嵌入$g_{ss}$。</p><script type="math/tex; mode=display">m_{v}^{t+1} = \sum_{w \epsilon N(v)} M_t(h_v^t,h_w^t,e_{vw})​</script><script type="math/tex; mode=display">h_v^{t+1} = U_t(h_v^t, m_v^{t+1})</script><script type="math/tex; mode=display">g_{ss} = R(h_v^T | v \epsilon G)</script><p>其中G代表整个图，v代表节点，N(v) 代表v的邻接节点。我们在消息函数M上使用MLP，在更新函数U上使用GRU来学习时间迭代的顺序信息。（Xu et al.2018）证明求和函数是读出函数R的最佳选择，因此我们使用求和函数，并提取第0步和第T步的图形表示。$h_v^0$表示BERT预训练生成的最初的块嵌入，$h_v^t$表示t步骤的块嵌入。</p><script type="math/tex; mode=display">m_v^{t+1} = \sum_{w \epsilon N(v)} MLP(h_w^t) ​</script><script type="math/tex; mode=display">h_v^{t+1} = GRU(h_v^t,m_v^{t+1})</script><script type="math/tex; mode=display">g_{ss} = \sum_{v \epsilon G}MLP(h_v^0,h_v^T)</script><h2 id="顺序感知模型"><a href="#顺序感知模型" class="headerlink" title="顺序感知模型"></a>顺序感知模型</h2><p>在这个部分中，我们的目标是解析CFG的节点顺序信息。 我们可以考虑CNN模型可以学到什么信息。图5展示了3个图（没有语义信息的块）和它们的邻接矩阵，这些邻接矩阵可以通过添加几个小的更改而彼此转换。在这三个图中，每个图都包含一个三角形。我们可以观察到在每个邻接矩阵中的三角形特征在邻接矩阵中具有一些共同的特征。首先考虑5a和5b，一个新的节点加入到三角形中，但是三角形的节点顺序没有被破坏。即使位移发生变化，两个相邻矩阵中的三角形特征（1，1，0，1的正方形）也不会改变。CNN可以捕获到这样的信息，因为当CNN看到许多训练数据时，它具有翻译不变性。在5c中，似乎添加的节点2破坏了三角形的节点顺序。但是，当我们看到邻接矩阵的第二行和第二列，三角形特征仍然存在。这就像图像缩放，如果我们把三角形特征的正方形看成2*2的图像，它可以被扩大成5c中3*3的图像。CNN在看到足够的训练数据后也可以学习这种尺度不变性。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://t1.picb.cc/uploads/2020/05/17/kYTCg1.png" alt="图5：示例图及其邻接矩阵" title>                </div>                <div class="image-caption">图5：示例图及其邻接矩阵</div>            </figure><p>我们已经讨论过，由于CNN的平移不变性和规模不变性，CNN可能会学习节点顺序的细微变化。在我们的二进制代码相似性检测任务中，当在不同平台上编译相同函数时，节点顺序通常不会发生太大变化。大部分节点顺序的变化就是增加一个节点、删除一个节点，或替换几个节点，所以CNN对我们的任务很有用。除了提高学习节点顺序信息的准确性外，CNN还具有其他一些优势。首先，相比于传统的图特征解析算法，直接将邻接矩阵用于CNN的速度更快。第二，CNN可以添加到具有不同大小的输入上，因此它可以对不同大小的图形进行建模，而无需诸如填充和剪切之类的预处理。</p><script type="math/tex; mode=display">g_o = Maxpooling(Resnet(A))</script><p>我们对邻接矩阵A使用Resnet（He et al.2016）。Resnet使用快捷连接来帮助信息轻松有效地传输。我们使用一个11层Resnet和3个剩余块。所有的特征映射都是3*3，因为我们像学习图中的微小变化。然后我们使用全局最大池化层来计算图顺序嵌入。 请注意，除非在最后一层，否则我们不使用任何池方法，因为输入有不同的大小。 在我们的实验中，我们观察到使用邻接矩阵的幂作为附加输入可以帮助提高性能。 为了防止过度拟合，我们在本文中不使用它们。（Nguyen）也在图上使用CNN，但是他们试图用CNN学习语义特征。我们的方法想用CNN学习节点顺序的特征，所以只使用邻接矩阵作为输入。</p><h1 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h1><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p> 我们在两个任务上评估我们的模型。第一个任务使跨平台二进制代码检测，相同的源代码在不同的平台上编译成不同的CFG，我们的目标是确保相同的源代码比其他源代码具有更高的相似性分数。与Gemini类似，我们在图嵌入模型上使用暹罗网络来减少损失，并使用余弦距离来计算图的相似性。我们选择x86-84和ARM两个平台，在gcc上用O2和O3编译选项。第二个任务使图分类任务， 我们对图嵌入的优化选项进行了分类。我们使用softmax函数，选择交叉熵作为损失函数。我们使用x86-64和ARM在gcc的O2和O3上编译。请注意，我们的方法对于检测不同编译器(例如：clang&amp;gcc)上的二进制代码也是有用的，在本文中我们不选择它作为数据集。数据集的基本统计数据如表1所示。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://t1.picb.cc/uploads/2020/05/17/kYTcGd.png" alt="表1" title>                </div>                <div class="image-caption">表1</div>            </figure><h2 id="对比方法"><a href="#对比方法" class="headerlink" title="对比方法"></a>对比方法</h2><p>由于我们的模型有三个组成部分：语义感知模型、结构感知模型和顺序感知模型，我们设计不同实验来验证每个部分的有效性。</p><p><strong>图核方法</strong> 我们选择使用Weisfeiler-Lehman kernel来计算图的相似性。</p><p><strong>Gemini</strong> 使用Structure2vec来计算CFG的图嵌入，其中每个块是一个8维度的手工选择的特征。</p><p><strong>MPNN</strong> 为了将我们的语义感知 &amp; 结构感知模型和Gemini对比，我们使用MPNN和8维度的特征。</p><p><strong>Word2vec</strong> Word2vec是NLP中学习词嵌入的最基本方法。我们将每个token的嵌入求和作为块嵌入。</p><p><strong>Skip thought</strong> skip thought是NLP中的另一个学习句子嵌入的方法，它接收中间句子作为输入，然后使用sequence-to-sequence模型来预测前面和后面的句子。</p><p><strong>BERT （2任务）</strong> 我们使用BERT预训练CFG的块嵌入，这两个预训练任务是MLM和ANP。</p><p><strong>BERT （4任务）</strong> 除了MLM和ANP任务，我们增加了两个图级别的任务（BIG和GC）来学习图级别的信息。</p><p><strong>基于CNN的方法</strong> 为了计算顺序感知模型的效果，我们只将CNN模型用于邻接矩阵。我们使用3层CNN，7层Resnet，11层Resnet来评估基于CNN的模型是否有用。为了减少参数、防止过拟合，我们不适用更大的CNN模型。</p><p><strong>CNN（随机）</strong> 为了查看CNN能否捕获节点顺序的信息，我们将CFG随机打乱，然后将相应的邻接矩阵输入到CNN中进行学习。</p><p><strong>MPNN（没有语义）</strong> Xu等人已经证明CNN模型可以学习图的结构信息，我们使用没有语义信息的MPNN，每个块都有一个相同的原始输入（一个随机向量）。</p><p><strong>MPNN（没有语义）+ CNN</strong> 我们将CNN节点顺序嵌入和CNN嵌入连接起来，来看这些模型在一起使用是否效果更好。</p><p><strong>本文方法</strong> BERT（4任务）+MPNN+11层Resnet，包括语义感知模型、结构感知模型和顺序感知模型。</p><p><strong>训练</strong> 使用Tensorflow实现模型，优化器使Adam，BERT预训练嵌入的维度是128，整个图的嵌入维度是64。BERT预训练最长的句子长度是128，transformer的深度是12，前馈dim是256。我们采用网格搜索来为每个带有验证集的模型找到最佳的超参数。我们模型的最佳优化设置是：learning rate：0.0001，batch size：10，iteration time steps：5。</p><p><strong>评价指标</strong> 对于任务1，我们的目标是找到在不同平台上由相同源代码编译的二进制代码。这个任务和推荐系统相似，我们使用Rank1和平均相互排名（mean reciprocal rank，MRR）作为评估指标。Rank1表示真实对的rank是否具有最高分数。MRR用于评估排名任务，该任务使用第一个正确答案的排名的乘积逆。任务2是分类任务，因此我们使用准确性来评估模型。</p><h2 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h2><h3 id="整体表现"><a href="#整体表现" class="headerlink" title="整体表现"></a>整体表现</h3><p>表2和表3展示了不同模型在两个任务上的整体表现。BERT2 &amp; 4 是BERT2个任务（MLM &amp; ANP）和4个任务（MLM &amp; ANP &amp; BIG &amp; GC）的缩写。$MPNN_{WS}$是没有语义的MPNN的缩写。第一个块包含前面的方法，第二个块展示了语义感知模型的结果，第三个块展示了顺序感知模型的结果。和Gemini对比，我们的模型在两个任务上的效果都更好。MPNN在所有数据集是上的表现都优于Gemini，这是因为GRU更新函数可以存储更多的信息，所有在所有其他模型中我们使用MPNN。我们可以观察到基于NLP的块预处理特征比手工选择的特征效果好很多，而且顺序感知模型也在两个任务上取得好效果。在跨平台二进制代码检测任务中，语义信息比顺序信息更加有用，不同的CFG可能有相似的节点顺序，所以只使用节点顺序信息是不足够的。最后，我们最终的模型比其他所有模型的效果都好，接下来我们分开调查每个组成部分的有效性。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://t1.picb.cc/uploads/2020/05/17/kYT1du.png" alt="表2" title>                </div>                <div class="image-caption">表2</div>            </figure><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://t1.picb.cc/uploads/2020/05/17/kYTGuD.png" alt="表3" title>                </div>                <div class="image-caption">表3</div>            </figure><h3 id="用于语义感知建模的模型变体"><a href="#用于语义感知建模的模型变体" class="headerlink" title="用于语义感知建模的模型变体"></a>用于语义感知建模的模型变体</h3><p>为了验证BERT预训练的必要性和有效性，我们学习了几个变体。首先，基于NLP的预训练块特征（word2vec，skip thought，BERT2 &amp; 4）比手工特征的效果好，这说明为CFG建立复杂模型是有必要的。和word2vec、skip thought对比，有MLM和ANP的BERT任务不仅考虑了块级别的预测，还有token级别的预测，而且双向transformer有更好的能力解析有用信息。BIG和GC任务也很有用，可以提高1%-2%的结果，在这两个任务中，块嵌入可以学习图级别的信息，这可以帮助图级别的任务。我们在图6中展示了块嵌入，4个CFG和他们的块嵌入被分为4个方向，我们采用K-means将这些块嵌入聚类成4个分类，不同的聚类有不同的颜色（红，蓝，绿，紫）。我们可以观察到相同图的块趋于拥有相同的颜色，而且不同的图有不同的主要颜色。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://t1.picb.cc/uploads/2020/05/18/kYUggw.png" alt="图6" title>                </div>                <div class="image-caption">图6</div>            </figure><h3 id="用于顺序感知建模的模型变体"><a href="#用于顺序感知建模的模型变体" class="headerlink" title="用于顺序感知建模的模型变体"></a>用于顺序感知建模的模型变体</h3><p>只是用基于CNN的模型可以在两个任务上获得好的结果。11层Resnet比3层CNN和7层Resnet的结果好一点，相比于$MPNN_{ws}$，基于CNN的模型效果更好。 当随机洗牌节点时，CNN什么也学不到。这说明CNN模型可以学习到图中的节点顺序，而且将邻接矩阵用于CNN解析节点顺序信息是很有意义的。此外，同时使用MPNN和CNN可以获得更好的效果，这说明我们的结构感知部分也很有效。为了探索CNN模型究竟学习到了什么，我们展示了一个CFG变化的例如，如图7所示。这两个CFG由同一段源代码编译而成，为了节省空间，我们展示不包含语义代码的图，左边是gcc和x86-64编译的，右边是gcc和ARM编译的。在不同平台下，代码被编译为不同的CFG，节点3在左图中被分开成了右图的节点3和4。在他们的邻接矩阵中，节点顺序“1，2，3”和“4，5，6”可以被捕获到。通过从邻接矩阵中解析特征，我们的CNN模型学习到这两个CFG的余弦相似度为0.971，而且整个平台上的代码检测等级为1，这表明CNN可以从邻接矩阵中学习到节点的顺序信息，这也符合我们的假设。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://t1.picb.cc/uploads/2020/05/18/kYUZdg.png" alt="图7" title>                </div>                <div class="image-caption">图7</div>            </figure><h1 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h1><p>本文我们提出了一个包含语义感知、结构感知和顺序感知的框架，用于二进制代码图学习。我们观察到语义和节点顺序都对CFG的表示有重要作用。为了捕获语义特征，我们使用BERT预训练CFG的块，使用两个原始任务MLM和ANP，和两个附加任务BIG和GC。然后我们使用MPNN来解析结构信息。我们进一步提出了基于CNN的模型用于捕获节点顺序信息，我们在4个数据集、2个任务上展开实验，结果表明我们提出的模型优于最先进的方法。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;figure class=&quot;image-bubble&quot;&gt;
                &lt;div class=&quot;img-lightbox&quot;&gt;
                    &lt;div class=&quot;overlay&quot;&gt;&lt;/div&gt;
                   
      
    
    </summary>
    
    
      <category term="Vulnerability Detection" scheme="https://cicilzx.github.io/tags/Vulnerability-Detection/"/>
    
      <category term="binary code similarity detection" scheme="https://cicilzx.github.io/tags/binary-code-similarity-detection/"/>
    
      <category term="neural networks" scheme="https://cicilzx.github.io/tags/neural-networks/"/>
    
  </entry>
  
  <entry>
    <title>Juliet Test Case代码集的使用</title>
    <link href="https://cicilzx.github.io/2020/02/26/Juliet-Test-Case%E4%BB%A3%E7%A0%81%E9%9B%86%E7%9A%84%E4%BD%BF%E7%94%A8/"/>
    <id>https://cicilzx.github.io/2020/02/26/Juliet-Test-Case代码集的使用/</id>
    <published>2020-02-26T02:40:47.000Z</published>
    <updated>2020-02-26T03:23:09.333Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Section-8-Tool-Analysis"><a href="#Section-8-Tool-Analysis" class="headerlink" title="Section 8: Tool Analysis"></a>Section 8: Tool Analysis</h2><p>Juliet Test Case测试用例集可用于方便地评估静态分析工具的结果。本节描述在测试用例上运行静态分析工具时所需的结果。</p><table>   <tr>      <td>混淆矩阵</td>      <td></td>      <td>实际结果</td>      <td></td>   </tr>   <tr>      <td></td>      <td></td>      <td>有BUG</td>      <td>无BUG</td>   </tr>   <tr>      <td>预测结果</td>      <td>有BUG</td>      <td>TP</td>      <td>FP</td>   </tr>   <tr>      <td></td>      <td>无BUG</td>      <td>FN</td>      <td>TN</td>   </tr>   <tr>      <td></td>   </tr></table><h3 id="True-Positive-and-False-Negatives"><a href="#True-Positive-and-False-Negatives" class="headerlink" title="True Positive and False Negatives"></a>True Positive and False Negatives</h3><p>函数名中出现“bad”的，例如bad()，badSink()，CWE476_NULL_Pointer_Dereference_char_41_bad()，或者是类名出现“bad”的，例如CWE401_Memory_Leak_destructor_01_bad.cpp，都是确实存在漏洞的。如果静态代码分析工具判断这类函数或类存在指定类型的漏洞，则结果为正报（TP），若没有报出漏洞，则是漏报（FN）。</p><h3 id="False-Positives-and-True-Negatives"><a href="#False-Positives-and-True-Negatives" class="headerlink" title="False Positives and True Negatives"></a>False Positives and True Negatives</h3><p>函数名或类名中出现”good“的，是没有漏洞的代码，如果静态代码分析工具报出漏洞，则是误报（FP）。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Section-8-Tool-Analysis&quot;&gt;&lt;a href=&quot;#Section-8-Tool-Analysis&quot; class=&quot;headerlink&quot; title=&quot;Section 8: Tool Analysis&quot;&gt;&lt;/a&gt;Section 8: Tool 
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>论文笔记:Mining Fix Patterns for FindBugs Violations</title>
    <link href="https://cicilzx.github.io/2020/02/15/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Mining-Fix-Patterns-for-FindBugs-Violations/"/>
    <id>https://cicilzx.github.io/2020/02/15/论文笔记-Mining-Fix-Patterns-for-FindBugs-Violations/</id>
    <published>2020-02-15T01:29:01.000Z</published>
    <updated>2020-02-16T05:25:52.346Z</updated>
    
    <content type="html"><![CDATA[<p>原文连接：<a href="https://arxiv.org/abs/1712.03201" target="_blank" rel="noopener">Mining Fix Patterns for FindBugs Violations</a></p><p>静态代码分析工具（如Splint，FindBugs）用于检测安全漏洞（security vulnerabilities）和不良编程做法（bad programming practices），但是这类工具存在较高的误报率（false positive rates）。静态代码分析工具产生的缺陷报告（violations），如果在项目的更新版本中被修复了，则该缺陷属于正报（true positive）；如果在项目的更新版本中仍然存在，则认为是误报。</p><p>本文收集了大量有迭代更新版本的项目，使用FindBugs工具扫描代码，并追踪漏洞报告的修复情况。本文提出了一种用CNN学习代码特征，并聚类重组相似实例的方法，来进行自动识别缺陷报告和修复的模式。</p><h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1 Introduction"></a>1 Introduction</h2><p><strong>假阳性报告出现的原因</strong>：</p><ol><li>不是严重的bug，不值得修复；</li><li>在运行环境中基本不容易发生；</li><li>由于静态扫描工具的固有缺陷，导致报告本身不正确。</li></ol><p><strong>本文的research questions（RQs）</strong>：</p><ul><li>RQ1：在项目中，报错行为在多大程度上再次发生？</li><li>RQ2：开发人员实际纠正了哪些类型的报错？（true positive）</li><li>RQ3：开发人员修复/不修复的漏洞代码的模式是什么？【构建模式，更好的帮助理解静态分析规则】</li><li>RQ4：当开发人员进行更改时，报错信息是如何解决的？【构建自动修复的解决方案】</li><li>RQ5：修复模式能帮助系统化解决类似的报错吗？</li></ul><blockquote><p>本文使用的工具一览：</p><p>漏洞扫描工具：FindBugs</p><p>数据集：730个来源Java工程（多个修复版本）</p><p>AST差分化工具GumTree（支持C和 Java）：收集修复变更情况</p><p>Word2Vec：将fixing change转化为空间向量</p><p>CNN：提取特征</p><p>X-means聚类算法：重组相似的修复变更</p><p>用于测试的数据：Defect4J，10个开源Java项目</p></blockquote><p><strong>Contributions</strong>：</p><ol><li>构建了数据集（FindBugs对730个项目的扫描结果和变更情况）</li><li>对FindBugs漏洞报告做了empirical study</li><li>Bug修复的模式挖掘</li><li>基于模式的Bug修复</li></ol><h2 id="2-Methodology"><a href="#2-Methodology" class="headerlink" title="2 Methodology"></a>2 Methodology</h2><p>总体来看，分为这几个步骤：</p><ol><li>将静态分析工具用于扫描代码，收集所有的漏洞报告</li><li>在历史版本中追踪每条漏洞报告的修复情况</li><li>识别哪些漏洞报告被修复了、哪些没有修复</li><li>挖掘会导致静态工具产生漏洞报告的代码模式</li><li>挖掘漏洞代码的修复模式</li></ol><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://i.loli.net/2020/02/15/l1TQ35EfVhJjdLb.png" alt="方法整体图" title>                </div>                <div class="image-caption">方法整体图</div>            </figure><h3 id="2-1-收集漏洞报告（-Collecting-violations"><a href="#2-1-收集漏洞报告（-Collecting-violations" class="headerlink" title="2.1 收集漏洞报告（ Collecting violations)"></a>2.1 收集漏洞报告（ Collecting violations)</h3><p>使用maven进行自动化构建项目，FindBugs作为扫描工具。对于每一个漏洞实例，记录6个信息：类型、实体（project，class，method）、提交版本号、文件路径、起始代码行、终止代码行。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://i.loli.net/2020/02/15/5kiJHGQrRgVqME1.png" alt="记录的XML格式" title>                </div>                <div class="image-caption">记录的XML格式</div>            </figure><h3 id="2-2-追踪漏洞报告（Tracking-violations）"><a href="#2-2-追踪漏洞报告（Tracking-violations）" class="headerlink" title="2.2 追踪漏洞报告（Tracking violations）"></a>2.2 追踪漏洞报告（Tracking violations）</h3><p>精准的追踪漏洞报告是比较困难的，因为一般静态扫描工具都是提供漏洞在文件中的代码行作为位置信息，在项目迭代更新之后，行数可能会有变化，所以用代码行来追踪漏洞报告是不准确的。本文使用的追踪方法参考<a href="https://ieeexplore.ieee.org/document/7194595" target="_blank" rel="noopener">Tracking Static Analysis Violations over Time to Capture Developer Characteristics</a>，此方法有三个匹配法则：</p><ol><li>基于位置的匹配（location-based matching）</li><li>基于代码片段的匹配（snippet-based matching）</li><li>基于哈希的匹配（hash-based matching）</li></ol><h3 id="2-3-识别修复模式（Identifying-fixed-violations）"><a href="#2-3-识别修复模式（Identifying-fixed-violations）" class="headerlink" title="2.3 识别修复模式（Identifying fixed violations）"></a>2.3 识别修复模式（Identifying fixed violations）</h3><p>追踪每一条漏洞报告，会有三种结果：</p><ol><li>由于漏洞报告指出的代码被删除，词条漏洞报告消失【unactionable violations】；</li><li>此条漏洞报告在最新版本的代码中依然存在（尽管有代码变更），这表明此条漏洞报告是误报【false positive】；</li><li>由于漏洞报告指出的代码有修改（包括删除），此条漏洞报告被修复了【actionable violations / true positive】。</li></ol><p>识别修复了的漏洞报告：从最早的版本开始追踪每个漏洞报告，如果某个版本不再报错，则识别为修复了报告信息，否则认为是未修复的报告信息。</p><h3 id="2-4-挖掘相似代码模式"><a href="#2-4-挖掘相似代码模式" class="headerlink" title="2.4 挖掘相似代码模式"></a>2.4 挖掘相似代码模式</h3><p>这个步骤主要是挖掘被漏洞扫描工具判别为有漏洞的（不考虑正报误报）相似代码模式。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://i.loli.net/2020/02/15/dHyN7IYckpzSLVv.png" alt="挖掘相似代码模式的整体流程图" title>                </div>                <div class="image-caption">挖掘相似代码模式的整体流程图</div>            </figure><h4 id="2-4-1-准备工作"><a href="#2-4-1-准备工作" class="headerlink" title="2.4.1 准备工作"></a>2.4.1 准备工作</h4><p>定义代码模式：</p><p><strong>定义1：源代码实体【Source Code Entity（Sce）】</strong></p><p>源代码实体表示AST上的一个节点，type是节点的类型，identifier是文本的表示。</p><blockquote><p>$Sce = (Type , Identifier)$</p></blockquote><p><strong>定义2：代码上下文【Code Context（Ctx）】</strong></p><p>代码上下文用于表示一个AST子树，包含3个属性：Sce指一个源代码实体（也就是一个节点）；$Sce_p$ 是指Sce的父节点（如果Sce是根节点，$Sce_p$ 就是空集）；cctx是指Ctx的子节点的列表（如果Sce是一个叶子节点，cctx就是空集)。</p><blockquote><p>$Ctx = (Sce, Sce_p , cctx)$</p></blockquote><p><strong>定义3：代码模式【Code Pattern（CP）】</strong></p><p>$Sce_a$ 是抽象节点的集合，$Sce_c​$ 是具体节点的集合，cctx是代码上下文的集合，用于描述此代码模式中所有节点之间的关系。</p><blockquote><p>$CP = (Sce_a , Sce_c , cctx)$</p></blockquote><h4 id="2-4-2-精炼AST"><a href="#2-4-2-精炼AST" class="headerlink" title="2.4.2 精炼AST"></a>2.4.2 精炼AST</h4><p>代码模式就是在精炼AST上提取的，节点上包含两个属性：节点类型和标识符。精炼AST的主要方法是消除SimpleName的节点，替换为其子节点，对于自定义的函数，节点类型改为Method；对于自定义的变量，类型改为Variable。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://i.loli.net/2020/02/15/tC3OBlSdAczwL2N.png" alt="精炼AST" title>                </div>                <div class="image-caption">精炼AST</div>            </figure><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://i.loli.net/2020/02/15/3Q9SD8qeOy7o5km.png" alt="精炼AST的算法" title>                </div>                <div class="image-caption">精炼AST的算法</div>            </figure><h4 id="2-4-3-数据处理"><a href="#2-4-3-数据处理" class="headerlink" title="2.4.3 数据处理"></a>2.4.3 数据处理</h4><p>FindBugs报的是出错的代码起止行，代码起止行可构成一个代码块，首先提取代码块的精炼AST，然后使用深度优先的方法遍历AST，提取节点的类型和标识符信息，形成一个token的序列。对于无意义的变量名，统一替换成变量类型和“Var”的拼接。</p><blockquote><p>例如，“int a”经过tokenized处理之后的向量是：（PrimitiveType，int，Variable，a）</p><p>然后处理变量，向量为（PrimitiveType，int，Variable，intVar）</p></blockquote><p>对于token序列，使用Word2Vec方法进行处理，把token序列中的每个单词转化为固定长度的向量，一个token序列对应一个二维数组，第一行代表第一个单词的向量，第二行代表第二个单词的向量，以此类推。然后用CNN神经网络进行特征化，最后每个token序列转化为一个固定长度的一维向量。对于特征向量，用X-means算法进行聚类，最后手工标记每个类簇的模式标签。</p><h3 id="2-5挖掘相似的漏洞修复模式"><a href="#2-5挖掘相似的漏洞修复模式" class="headerlink" title="2.5挖掘相似的漏洞修复模式"></a>2.5挖掘相似的漏洞修复模式</h3><p> 这一部分主要是研究存在漏洞的代码是怎么被修复的，整体思路和挖掘相似代码模式相近，但是在数据收集、tokenization这两部分有所区别。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://i.loli.net/2020/02/16/sqoFVmHTviCztLI.png" alt="相似漏洞修复模式的流程" title>                </div>                <div class="image-caption">相似漏洞修复模式的流程</div>            </figure><h4 id="2-5-1-准备工作"><a href="#2-5-1-准备工作" class="headerlink" title="2.5.1 准备工作"></a>2.5.1 准备工作</h4><p><strong>定义4：补丁【 Patch（P）】</strong></p><p>补丁是一对源代码片段，一个代表有bug的版本（代码行的开头用 “-” 表示），一个代表修复了的版本（代码行的开头用 “+” 表示）。</p><p>$Frag_b$ 代表有bug的版本，$Frag_f$ 代表修复的版本，这两个版本可以分别为空集，但是不能同时为空集。如果有bug的版本是空，那么补丁一定是添加了一行或多行代码；如果修复版本是空集，那么原始版本一定是删除了一行或多行代码。</p><blockquote><p>$P = (Frag_b, Frag_f)$</p></blockquote><p>对于补丁，还需要进行抽象化的处理（例如使用统一名称表示变量和自定义的函数），以便用于解决其他类似的bug。抽象的补丁被定义为修复模式。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://i.loli.net/2020/02/16/EmnU79FbL2QC4dG.png" alt="补丁" title>                </div>                <div class="image-caption">补丁</div>            </figure><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://i.loli.net/2020/02/16/EmnU79FbL2QC4dG.png" alt="抽象的补丁" title>                </div>                <div class="image-caption">抽象的补丁</div>            </figure><p><strong>定义5：修复模式【 Fix Pattrn（FP）】</strong></p><blockquote><p>$FP = (Ctx , CO)$</p><p>Ctx表示代码上下文，CO表示变更操作的集合。</p></blockquote><p><strong>定义6：变更操作【 Change Operation （O）】</strong></p><blockquote><p>$O = (Action, Sce, CO)$</p><p>Action是动作集合（UPD更新,DEL删除,INS插入,MOV移动）中的一个元素，作用在代码实体（Sce）上。CO是当前操作实体的子节点，对应的子更新操作集合，如果当前操作的实体就是叶子节点，那么CO就是空集。</p></blockquote><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://i.loli.net/2020/02/16/fcwDKAjsn7XiLg1.png" alt="变更操作的实例" title>                </div>                <div class="image-caption">变更操作的实例</div>            </figure><h4 id="2-5-2-模式挖掘处理"><a href="#2-5-2-模式挖掘处理" class="headerlink" title="2.5.2 模式挖掘处理"></a>2.5.2 模式挖掘处理</h4><p>常见的修复模式可以从大型更改集中挖掘出来。本文设计了一种方法来挖掘静态分析漏洞报告的常见修复模式，方法是提取开发人员手动更正的更改。</p><p>补丁的代码更改被描述为一组以抽象语法树（AST）差异（即AST Diffs）的形式进行的更改操作。GNU diffs是用纯基于文本的一行一行编辑的脚本表示代表变更，而AST Diffs提供一种启发式的代码表示，描述代码实体不同等级（statements，expressions，elements）的变更情况，本文使用GumTree工具来解析和描述补丁的代码变更情况。</p><p>所有补丁都被标记为文本向量，方法是使用深度优先搜索算法遍历其AST级别的diff树，并提取动作字符串（如UPD），实体类型（如Return Statement），和实体标识符（如return），作为更改动作的tokens（如UPD ReturnStatement return），接下来从token转为特征向量的方法和前文的方法相同（Word2Vec+CNN）。然后用X-means算法聚类，每个类簇就是一种模式。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;原文连接：&lt;a href=&quot;https://arxiv.org/abs/1712.03201&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Mining Fix Patterns for FindBugs Violations&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;静态代
      
    
    </summary>
    
    
      <category term="Vulnerability Detection" scheme="https://cicilzx.github.io/tags/Vulnerability-Detection/"/>
    
      <category term="program repair" scheme="https://cicilzx.github.io/tags/program-repair/"/>
    
      <category term="pattern mining" scheme="https://cicilzx.github.io/tags/pattern-mining/"/>
    
  </entry>
  
  <entry>
    <title>论文笔记-VulDeePecker: A Deep Learning-Based System for Vulnerability Detection</title>
    <link href="https://cicilzx.github.io/2019/10/27/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-VulDeePecker-A-Deep-Learning-Based-System-for-Vulnerability-Detection/"/>
    <id>https://cicilzx.github.io/2019/10/27/论文笔记-VulDeePecker-A-Deep-Learning-Based-System-for-Vulnerability-Detection/</id>
    <published>2019-10-27T04:27:46.000Z</published>
    <updated>2019-10-27T06:40:37.815Z</updated>
    
    <content type="html"><![CDATA[<figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://t1.picb.cc/uploads/2019/10/27/gERMJ1.png" alt="gERMJ1.png" title>                </div>                <div class="image-caption">gERMJ1.png</div>            </figure><p>原文链接：<a href="https://arxiv.org/pdf/1801.01681.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1801.01681.pdf</a></p><h1 id="1-主要内容"><a href="#1-主要内容" class="headerlink" title="1 主要内容"></a>1 主要内容</h1><p>本文设计并实现了基于深度学习的漏洞检测系统，叫做vulnerability deep pecker（VulDeePecker）。目前主流的漏洞检测方案都是依赖人的经验去定义特征，这种方式会导致较高的漏报率，因此本文提出使用深度学习来进行漏洞检测，VulDeePecker相比于其他自动化漏洞检测工具，误报率更低，能够判断是否有漏洞，并定位到漏洞的位置，可同时检测多个漏洞。如果结合人类专家的知识，可以进一步提高漏洞检测的有效性。用于评估的漏洞数据集来自：<a href="https://github.com/CGCL-codes/VulDeePecker" target="_blank" rel="noopener">https://github.com/CGCL-codes/VulDeePecker</a></p><h2 id="1-1-基于深度学习的漏洞检测指导原则"><a href="#1-1-基于深度学习的漏洞检测指导原则" class="headerlink" title="1.1 基于深度学习的漏洞检测指导原则"></a>1.1 基于深度学习的漏洞检测指导原则</h2><h3 id="1-1-1-如何表示软件程序？"><a href="#1-1-1-如何表示软件程序？" class="headerlink" title="1.1.1 如何表示软件程序？"></a>1.1.1 如何表示软件程序？</h3><p>由于深度学习或神经网络需要使用向量做为输入，所以需要将程序转化为有语义相关的向量。</p><p><strong>指导原则1</strong>：程序先转换为保存了程序元素间（如数据依赖和控制依赖）语意关系的中间表达（命名为code gadget），然后这个中间表达可以转化为一个向量表达，作为神经网络的实际输入。</p><h3 id="1-1-2-什么是合适的粒度？"><a href="#1-1-2-什么是合适的粒度？" class="headerlink" title="1.1.2 什么是合适的粒度？"></a>1.1.2 什么是合适的粒度？</h3><p>由于不仅需要检测这个程序是否存在漏洞，还要定位到具体漏洞的位置，所以需要一个合适的粒度来进行检测。</p><p><strong>指导原则2</strong>：为了帮助确定漏洞位置，程序应该以一个合适的粒度来表达，而非一个程序或一个函数作为一个单元。</p><h3 id="1-1-3-怎么选择神经网络？"><a href="#1-1-3-怎么选择神经网络？" class="headerlink" title="1.1.3 怎么选择神经网络？"></a>1.1.3 怎么选择神经网络？</h3><p>神经网络在图像处理、语言识别和自然语言处理领域非常成功，但是这些都不同于漏洞检测，这意味着许多神经网络不适合漏洞检测。</p><p><strong>指导原则3</strong>：确定这行代码是否存在漏洞需要依赖上下文环境。那些可以处理上下文环境的神经网络可能适合用来做漏洞检测。这条原则建议自然语言处理的神经网络可能适合用作漏洞检测。作者经过比对，选择了双向的LSTM来进行漏洞检测，也就是BLSTM。BLSTM神经网络的模型如下图。</p><p>[<figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://www.picb.cc/image/gEx2fF" alt="gEx2fF.png](https://t1.picb.cc/uploads/2019/10/27/gEx2fF.png)" title>                </div>                <div class="image-caption">gEx2fF.png](https://t1.picb.cc/uploads/2019/10/27/gEx2fF.png)</div>            </figure></p><h2 id="1-2-VulDeePecker的设计"><a href="#1-2-VulDeePecker的设计" class="headerlink" title="1.2 VulDeePecker的设计"></a>1.2 VulDeePecker的设计</h2><h3 id="1-2-1-定义code-gadget"><a href="#1-2-1-定义code-gadget" class="headerlink" title="1.2.1 定义code gadget"></a>1.2.1 定义code gadget</h3><p>code gadget由许多程序语句组成，他们在数据依赖或控制依赖方面的语义上彼此相关。为了产生code gadget，作者提出key point这个启发性的概念。Key point指代那些不正确的使用所造成漏洞的库/API函数。需要注意的是一种类型的漏洞可能有多种key point。同时同样类型的key point可能存在于多种类型的漏洞中。对应于库/ API函数调用的key point，code gadget可以通过数据流或程序的控制流分析来生成，其中存在众所周知的算法和易于使用的商业产品，例如Checkmarx。</p><h3 id="1-2-2-VulDeePecker的概述"><a href="#1-2-2-VulDeePecker的概述" class="headerlink" title="1.2.2 VulDeePecker的概述"></a>1.2.2 VulDeePecker的概述</h3><p>VulDeePecker有两个阶段：学习阶段和检测阶段。</p><p><strong>学习阶段</strong>：输入是大量的训练程序，一些是存在一个或多个已知漏洞的，一些则是安全的程序。学习阶段共包含4个步骤。</p><p><strong>步骤一：提取库/API函数调用以及对应的程序切片</strong></p><ul><li>步骤1.1 ：从训练用的程序中提取库/API函数调用</li><li>步骤1.2 ：从步骤1.1中提取的库/API函数中，为每一个参数（或变量）提取一个或多个程序切片。</li></ul><p><strong>步骤二：生成训练程序的code gadget和他们的标签</strong></p><ul><li>步骤2.1 ：汇编步骤1.2获取的程序切片为code gadget，一个code gadget并不一定对应于一系列连续的代码行。相反, 它包含的是语义相关的多行代码（例如, 继承了编码在那些程序切片中的语义关系）</li><li>步骤2.2 ：标记code gadget的真实值，标记为1表示存在漏洞，0表示没有漏洞。标记的方法让我们知道训练用的程序哪些是存在漏洞的，如果存在漏洞，也知道漏洞所在的具体位置。</li></ul><p><strong>步骤三：将code gadget转变为向量表示</strong></p><ul><li>步骤3.1：转换code gadget为确定的符号表示，该步骤目的在于保留训练用程序的一些语义信息</li><li>步骤3.2：对步骤3.1获得的符号表示, 将code gadget编码为向量, 作为训练BLSTM神经网络的输入。</li></ul><p><strong>步骤4：训练BLSTM神经网络</strong></p><p>[<figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://www.picb.cc/image/gExZjd" alt="gExZjd.png](https://t1.picb.cc/uploads/2019/10/27/gExZjd.png)" title>                </div>                <div class="image-caption">gExZjd.png](https://t1.picb.cc/uploads/2019/10/27/gExZjd.png)</div>            </figure></p><p><strong>检测阶段</strong>：给定一个或多个目标程序，我们提取它的库/API函数调用以及对应的程序切片，并将程序切片汇编为code gadget。code gadget转化成符号表示再编码为向量输入给训练好的BLSTM神经网络。神经网络会输出哪些向量，也就是哪些code gadget是存在漏洞的（“1”）或不存在漏洞（“0”）。如果一个code gadget存在漏洞，也就能确定下来目标程序中的漏洞位置。</p><p><strong>步骤5：转化目标程序为code gadget和向量</strong></p><ul><li>步骤 5.1: 从目标程序提取库/API函数调用</li><li>步骤 5.2: 根据库/API函数调用的参数提取出程序切片</li><li>步骤 5.3: 将程序切片汇编为code gadget</li><li>步骤 5.4: 转化code gadget对应的符号表示</li><li>步骤 5.5: 将code gadget的符号表示编码为向量</li></ul><p><strong>步骤6：检测</strong></p><p>使用训练好的BLSTM神经网络对目标程序提取得到的code gadget对应的向量进行分类。如果分类结果是1，表明存在漏洞，标记为0，表明不存在漏洞。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://t1.picb.cc/uploads/2019/10/27/gExIvD.png" alt="gExIvD.png" title>                </div>                <div class="image-caption">gExIvD.png</div>            </figure><h2 id="1-3-实验及结论"><a href="#1-3-实验及结论" class="headerlink" title="1.3 实验及结论"></a>1.3 实验及结论</h2>]]></content>
    
    <summary type="html">
    
      
      
        &lt;figure class=&quot;image-bubble&quot;&gt;
                &lt;div class=&quot;img-lightbox&quot;&gt;
                    &lt;div class=&quot;overlay&quot;&gt;&lt;/div&gt;
                   
      
    
    </summary>
    
    
      <category term="Vulnerability Detection" scheme="https://cicilzx.github.io/tags/Vulnerability-Detection/"/>
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="https://cicilzx.github.io/2019/08/31/hello-world/"/>
    <id>https://cicilzx.github.io/2019/08/31/hello-world/</id>
    <published>2019-08-31T08:48:37.953Z</published>
    <updated>2019-08-31T08:48:37.954Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.
      
    
    </summary>
    
    
  </entry>
  
</feed>
